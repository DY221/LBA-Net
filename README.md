Codes of the LBA_Net
Accurate yet efficient segmentation of breast ultrasound (BUS) images is essential for early tumour diagnosis, but is still hampered by speckle noise, low-contrast and ill-defined lesion boundaries. Although deep learning models have improved accuracy, their prohibitive complexity limits deployment on portable or edge devices. We propose LBA-Net, a lightweight boundary-aware network that delivers competitive accuracy with minimal computational cost. Built upon a MobileNetV3-Small encoder, LBA-Net employs a multi-scale ASPP module and a novel LBA-Block that fuses efficient channel and spatial attention to enhance tumour features while suppressing noise. A dual-head decoder, supervised by a boundary-sensitive composite loss, further refines contour precision. On the public BUSI(Breast Ultrasound Images) dataset (780 lesion images with masks), five-fold cross-validation yields a mean Dice of 93.36% and IoU of 88.76%—among the highest results reported for models under 5 GFLOPs. The network contains only 1.98 M parameters and 3.34 GFLOPs per inference, @512×512 input. Real-time benchmarking on an NVIDIA A100 shows 122 FPS (FP32, batch=1) and 779 FPS (torch.compile + FP16, batch=1), scaling to 1943 samples s⁻¹ at batch=4; even on Intel Xeon CPU (single-thread) it reaches 8.6 FPS, enabling point-of-care deployment.
<img width="643" height="358" alt="image" src="https://github.com/user-attachments/assets/74015325-35a9-41f8-8240-6de7de87f4d9" />
